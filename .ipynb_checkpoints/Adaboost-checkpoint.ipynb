{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer\n",
    "import DesicionTree as dt\n",
    "import Dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bagging_RSM(x, y, port):\n",
    "    features =[]\n",
    "    while not features:\n",
    "        for i in range(x.shape[1]):\n",
    "            checkf = np.random.randint(3)\n",
    "            if checkf == 1:\n",
    "                features.append(i)\n",
    "    newx, newy = [], []\n",
    "    \n",
    "    for s in range(x.shape[0]):\n",
    "        check = np.random.randint(port)\n",
    "        if check == 1:\n",
    "            xx = []\n",
    "            for f in features:\n",
    "                xx.append(x[s][f])\n",
    "            newx.append(np.asarray(xx))\n",
    "            newy.append(y[s])\n",
    "    return np.asarray(newx), np.asarray(newy), features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_weak_cls(X, tree):\n",
    "    return dt.predict(tree[0], X[tree[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree(X, Y, max_depth, min_size, port):\n",
    "    X, Y, features = Bagging_RSM(X, Y, port)\n",
    "    return dt.get_tree(X, Y, max_depth, min_size), features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(X, Y, W, tree, features):\n",
    "    Qsum = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        b = dt.predict(tree, X[i, features])\n",
    "        I = 1 if (Y[i]*b) < 0 else 0\n",
    "        Qsum += W[i] * I\n",
    "    return Qsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(Q):\n",
    "    return 0.5 * np.log((1-Q)/Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, Y, num_weak_clf, T, port, max_depth_range=3, min_size_range=3, alphas = [], bs = [], w = []):\n",
    "    #1 инициализация весов объектов\n",
    "    if not len(w):\n",
    "        w = np.asarray([1/X.shape[0] for i in range(X.shape[0])])\n",
    "    else:\n",
    "        alphas = list(alphas)\n",
    "        bs = list(bs)\n",
    "    \n",
    "    #2 Для всех t=1,...,T, пока не выполнен критерий останова.\n",
    "    while len(alphas) < num_weak_clf:     \n",
    "        #2.1 Находим классификатор b_t: X->{-1,+1} который минимизирует взвешенную ошибку классификации;\n",
    "        #b_t = argmin_b Q(b,W^l);\n",
    "        Qs = []\n",
    "        trees = []\n",
    "        for i in range(T):\n",
    "            tree, features = make_tree(X, Y, 1+np.random.randint(max_depth_range), 1+np.random.randint(min_size_range), port)\n",
    "            trees.append((tree, features))\n",
    "            Qs.append(Q(X, Y, w, tree, features))\n",
    "            \n",
    "        Qs = np.asarray(Qs)\n",
    "        argmin = np.argmin(Qs)\n",
    "        \n",
    "        if Qs[argmin]> 0.5:\n",
    "            pass\n",
    "        else:\n",
    "            bs.append(trees[argmin])\n",
    "            #2.2 Пересчитываем кооэффициент взвешенного голосования для алгоритма классификации b_t:\n",
    "\n",
    "            alpha_t = alpha(Qs[argmin])\n",
    "            alphas.append(alpha_t)\n",
    "\n",
    "            #2.3 Пересчет весов объектов: w_i = w_i*exp(-alpha_t*y_i*b_t(x_i)), i = 1,...,l\n",
    "            for i in range(w.shape[0]):\n",
    "                b = tree_weak_cls(X[i], trees[argmin])\n",
    "                w[i] *= np.exp(-alpha_t*Y[i]*b)\n",
    "\n",
    "            #2.4 Нормировка весов объектов:\n",
    "\n",
    "            w0 = np.sum(w)\n",
    "            for ww in w:\n",
    "                ww/=w0\n",
    "            \n",
    "            print('--------------------------')\n",
    "            print('Was made {num}th weak clfs:'.format(num=len(alphas)))\n",
    "            dt.print_tree(trees[argmin][0])\n",
    "            print('With features: {fs}'.format(fs=trees[argmin][1]))\n",
    "            print('--------------------------\\n\\n')\n",
    "    return np.asarray(alphas), np.asarray(bs), w\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, alphas, tree):\n",
    "    tmp_sum = 0\n",
    "    for t in range(alphas.shape[0]):\n",
    "        b = tree_weak_cls(X, tree=tree[t])\n",
    "        tmp_sum += alphas[t] * b\n",
    "    return np.sign(tmp_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    counter = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            counter +=1\n",
    "    return counter/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_progress(X, Y, alphas, bs):\n",
    "    progress = []\n",
    "    for i in range(1, len(alphas)+1):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            predictions.append(predict(x, alphas[0:i], bs[0:i]))\n",
    "        acc = accuracy(Y, predictions)\n",
    "        print('accurecy({T} weak clfs): {acc}\\n'.format(acc = acc,T=i))\n",
    "        progress.append(acc)\n",
    "    plt.plot(progress)\n",
    "    #plt.yticks(np.arange(0, 1.0, 0.1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary:\n",
      " {'1': {'Self-emp-not-inc': 0, 'Private': 1, 'State-gov': 2, 'Federal-gov': 3, 'Local-gov': 4, '?': nan, 'Self-emp-inc': 5, 'Without-pay': 6, 'Never-worked': 7}, '3': {'Bachelors': 0, 'HS-grad': 1, '11th': 2, 'Masters': 3, '9th': 4, 'Some-college': 5, 'Assoc-acdm': 6, 'Assoc-voc': 7, '7th-8th': 8, 'Doctorate': 9, 'Prof-school': 10, '5th-6th': 11, '10th': 12, '1st-4th': 13, 'Preschool': 14, '12th': 15}, '5': {'Married-civ-spouse': 0, 'Divorced': 1, 'Married-spouse-absent': 2, 'Never-married': 3, 'Separated': 4, 'Married-AF-spouse': 5, 'Widowed': 6}, '6': {'Exec-managerial': 0, 'Handlers-cleaners': 1, 'Prof-specialty': 2, 'Other-service': 3, 'Adm-clerical': 4, 'Sales': 5, 'Craft-repair': 6, 'Transport-moving': 7, 'Farming-fishing': 8, 'Machine-op-inspct': 9, 'Tech-support': 10, '?': nan, 'Protective-serv': 11, 'Armed-Forces': 12, 'Priv-house-serv': 13}, '7': {'Husband': 0, 'Not-in-family': 1, 'Wife': 2, 'Own-child': 3, 'Unmarried': 4, 'Other-relative': 5}, '8': {'White': 0, 'Black': 1, 'Asian-Pac-Islander': 2, 'Amer-Indian-Eskimo': 3, 'Other': 4}, '9': {'Male': 0, 'Female': 1}, '13': {'United-States': 0, 'Cuba': 1, 'Jamaica': 2, 'India': 3, '?': nan, 'Mexico': 4, 'South': 5, 'Puerto-Rico': 6, 'Honduras': 7, 'England': 8, 'Canada': 9, 'Germany': 10, 'Iran': 11, 'Philippines': 12, 'Italy': 13, 'Poland': 14, 'Columbia': 15, 'Cambodia': 16, 'Thailand': 17, 'Ecuador': 18, 'Laos': 19, 'Taiwan': 20, 'Haiti': 21, 'Portugal': 22, 'Dominican-Republic': 23, 'El-Salvador': 24, 'France': 25, 'Guatemala': 26, 'China': 27, 'Japan': 28, 'Yugoslavia': 29, 'Peru': 30, 'Outlying-US(Guam-USVI-etc)': 31, 'Scotland': 32, 'Trinadad&Tobago': 33, 'Greece': 34, 'Nicaragua': 35, 'Vietnam': 36, 'Hong': 37, 'Ireland': 38, 'Hungary': 39, 'Holand-Netherlands': 40}}\n",
      "\n",
      "Train data:\n",
      "           0    1         2    3     4    5     6    7    8    9       10   11    12   13   14\n",
      "0      50.0  0.0   83311.0  0.0  13.0  0.0   0.0  0.0  0.0  0.0      0.0  0.0  13.0  0.0 -1.0\n",
      "1      38.0  1.0  215646.0  1.0   9.0  1.0   1.0  1.0  0.0  0.0      0.0  0.0  40.0  0.0 -1.0\n",
      "2      53.0  1.0  234721.0  2.0   7.0  0.0   1.0  0.0  1.0  0.0      0.0  0.0  40.0  0.0 -1.0\n",
      "3      28.0  1.0  338409.0  0.0  13.0  0.0   2.0  2.0  1.0  1.0      0.0  0.0  40.0  1.0 -1.0\n",
      "4      37.0  1.0  284582.0  3.0  14.0  0.0   0.0  2.0  0.0  1.0      0.0  0.0  40.0  0.0 -1.0\n",
      "...     ...  ...       ...  ...   ...  ...   ...  ...  ...  ...      ...  ...   ...  ...  ...\n",
      "32555  27.0  1.0  257302.0  6.0  12.0  0.0  10.0  2.0  0.0  1.0      0.0  0.0  38.0  0.0 -1.0\n",
      "32556  40.0  1.0  154374.0  1.0   9.0  0.0   9.0  0.0  0.0  0.0      0.0  0.0  40.0  0.0  1.0\n",
      "32557  58.0  1.0  151910.0  1.0   9.0  6.0   4.0  4.0  0.0  1.0      0.0  0.0  40.0  0.0 -1.0\n",
      "32558  22.0  1.0  201490.0  1.0   9.0  3.0   4.0  3.0  0.0  0.0      0.0  0.0  20.0  0.0 -1.0\n",
      "32559  52.0  5.0  287927.0  1.0   9.0  0.0   0.0  2.0  0.0  1.0  15024.0  0.0  40.0  0.0  1.0\n",
      "\n",
      "[32560 rows x 15 columns]\n",
      "\n",
      "Test data:\n",
      "           0    1         2    3     4    5    6    7    8    9      10   11    12    13   14\n",
      "0      38.0  4.5   89814.0  8.0   9.0  3.5  7.5  3.0  2.5  1.0     0.0  0.0  50.0  21.0 -1.0\n",
      "1      28.0  4.5  336951.0  8.0  12.0  3.5  7.5  3.0  2.5  1.0     0.0  0.0  40.0  21.0 -1.0\n",
      "2      44.0  4.5  160323.0  8.0  10.0  3.5  7.5  3.0  2.5  1.0  7688.0  0.0  40.0  21.0 -1.0\n",
      "3      18.0  4.5  103497.0  8.0  10.0  3.5  7.5  3.0  2.5  1.0     0.0  0.0  30.0  21.0 -1.0\n",
      "4      34.0  4.5  198693.0  8.0   6.0  3.5  7.5  3.0  2.5  1.0     0.0  0.0  30.0  21.0 -1.0\n",
      "...     ...  ...       ...  ...   ...  ...  ...  ...  ...  ...     ...  ...   ...   ...  ...\n",
      "16275  39.0  4.5  215419.0  8.0  13.0  3.5  7.5  3.0  2.5  1.0     0.0  0.0  36.0  21.0 -1.0\n",
      "16276  64.0  4.5  321403.0  8.0   9.0  3.5  7.5  3.0  2.5  1.0     0.0  0.0  40.0  21.0 -1.0\n",
      "16277  38.0  4.5  374983.0  8.0  13.0  3.5  7.5  3.0  2.5  1.0     0.0  0.0  50.0  21.0 -1.0\n",
      "16278  44.0  4.5   83891.0  8.0  13.0  3.5  7.5  3.0  2.5  1.0  5455.0  0.0  40.0  21.0 -1.0\n",
      "16279  35.0  4.5  182148.0  8.0  13.0  3.5  7.5  3.0  2.5  1.0     0.0  0.0  60.0  21.0 -1.0\n",
      "\n",
      "[16280 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = ds.get_dataset()\n",
    "alphas, bs, w = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_wclfs = 4\n",
    "start_time = time.time()\n",
    "alphas, bs, w = fit(X=x_train, Y=y_train, num_weak_clf=num_wclfs, T=10, port=100, \n",
    "                    max_depth_range=10, min_size_range=10, alphas=alphas, bs=bs, w=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\\n\" % (time.time() - start_time))\n",
    "plot_progress(x_test, y_test, alphas, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('meta1.pkl', 'wb') as f:\n",
    "    pickle.dump((alphas, bs, w), f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
